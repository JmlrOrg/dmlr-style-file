\documentclass[twoside,11pt]{article}

\usepackage{blindtext}

% Acknowledgements: This template is almost identical to that of Journal of Machine Learning Research https://github.com/JmlrOrg/jmlr-style-file
% Any additional packages needed should be included after dmlr.
% Note that dmlr2e.sty includes epsfig, amssymb, natbib and graphicx,
% and defines many common macros, such as 'proof' and 'example'.
%
% It also sets the bibliographystyle to plainnat; for more information on
% natbib citation styles, see the natbib documentation, a copy of which
% is archived at http://www.dmlr.org/format/natbib.pdf

% Available options for package dmlr2e are:
%
%   - abbrvbib : use abbrvnat for the bibliography style
%   - nohyperref : do not load the hyperref package
%   - preprint : remove DMLR specific information from the template,
%         useful for example for posting to preprint servers.
%
% Example of using the package with custom options:
%
% \usepackage[abbrvbib, preprint]{dmlr2e}

\usepackage{dmlr2e}

% Definitions of handy macros can go here

\newcommand{\dataset}{{\cal D}}
\newcommand{\fracpartial}[2]{\frac{\partial #1}{\partial  #2}}

% Heading arguments are {volume}{year}{pages}{date submitted}{date published}{paper id}{author-full-names}

\usepackage{lastpage}
\dmlrheading{23}{2023}{1-\pageref{LastPage}}{9/23; Revised 10/23}{11/23}{21-0000}{Author One and Author Two} % Insert the dates and author names. This is not relevant if it is yet being reviewed, i.e., \documentclass[twoside,11pt, preprint]{article}
\def\openreview{\url{https://openreview.net/forum?id=XXXX}} % Insert correct link to OpenReview for camera-ready version
% Short headings should be running head and authors last names

\ShortHeadings{Sample DMLR Paper}{One and Two}
\firstpageno{1}

\begin{document}

\title{Sample DMLR Paper}

\author{\name Author One \email one@stat.washington.edu \\
       \addr Department of Statistics\\
       University of Washington\\
       Seattle, WA 98195-4322, USA
       \AND
       \name Author Two \email two@cs.berkeley.edu \\
       \addr Division of Computer Science\\
       University of California\\
       Berkeley, CA 94720-1776, USA}

\editor{My editor}

\maketitle

\begin{abstract}%   <- trailing '%' for backward compatibility of .sty file
\blindtext
\end{abstract}

\begin{keywords}
  keyword one, keyword two, keyword three
\end{keywords}

\section{Introduction}

\blindmathpaper

Here is a citation \cite{chow:68}.


% Manual newpage inserted to improve layout of sample file - not
% needed in general before appendices/bibliography.
\impact{Authors must include a Broader Impact Statement, which should provide a concise, tangible portrayal of both the potential positive and negative societal consequences of their work. We refer to the submission guidelines for further details.}

% Acknowledgements and Disclosure of Funding should go at the end, before appendices and references

\acks{All acknowledgements go at the end of the paper before appendices and references.
Moreover, you are required to declare funding (financial activities supporting the
submitted work) and competing interests (related financial activities outside the submitted work).
More information about this disclosure can be found on the DMLR website.}

\vskip 0.2in
\bibliography{sample}

\appendix
\section{}
\label{app:theorem}

% Note: in this sample, the section number is hard-coded in. Following
% proper LaTeX conventions, it should properly be coded as a reference:

%In this appendix we prove the following theorem from
%Section~\ref{sec:textree-generalization}:

In this appendix we prove the following theorem from
Section~6.2:

\noindent
{\bf Theorem} {\it Let $u,v,w$ be discrete variables such that $v, w$ do
not co-occur with $u$ (i.e., $u\neq0\;\Rightarrow \;v=w=0$ in a given
dataset $\dataset$). Let $N_{v0},N_{w0}$ be the number of data points for
which $v=0, w=0$ respectively, and let $I_{uv},I_{uw}$ be the
respective empirical mutual information values based on the sample
$\dataset$. Then
\[
	N_{v0} \;>\; N_{w0}\;\;\Rightarrow\;\;I_{uv} \;\leq\;I_{uw}
\]
with equality only if $u$ is identically 0.} \hfill\BlackBox

\section{}

\noindent
{\bf Proof}. We use the notation:
\[
P_v(i) \;=\;\frac{N_v^i}{N},\;\;\;i \neq 0;\;\;\;
P_{v0}\;\equiv\;P_v(0)\; = \;1 - \sum_{i\neq 0}P_v(i).
\]
These values represent the (empirical) probabilities of $v$
taking value $i\neq 0$ and 0 respectively.  Entropies will be denoted
by $H$. We aim to show that $\fracpartial{I_{uv}}{P_{v0}} < 0$....\\


\end{document}
